{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENG474_Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1unfxqKkm7ZCFTN-3zEBj-Ge6oA4Wo6GD",
      "authorship_tag": "ABX9TyOKvquoJpGqMp5Y3k6UuvWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zt55699/Dataset/blob/main/SENG474_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nA0J-lrUOF"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Foc-VvDWgttf",
        "outputId": "8648515f-b1fd-4ff9-dc08-619fe584e87d"
      },
      "source": [
        "%rm -rf IMDB-Sentiment\n",
        "!git clone https://github.com/zt55699/IMDB-Sentiment.git\n",
        "%cd IMDB-Sentiment/\n",
        "%ls"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IMDB-Sentiment'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 2), reused 7 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n",
            "/content/IMDB-Sentiment/IMDB-Sentiment\n",
            "labeledTrainData.tsv  SENG474_Word2Vec.ipynb  unlabeledTrainData.tsv\n",
            "README.md             testData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7K9BddCnqVz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read data from files \n",
        "train_data = pd.read_csv( \"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
        "test_data = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
        "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1o8MWtDqUnF",
        "outputId": "f0c6759b-7fe3-4473-89cc-d06c394061c1"
      },
      "source": [
        "print(train_data.head)\n",
        "print(test_data.head)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of               id  sentiment                                             review\n",
            "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
            "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
            "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
            "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
            "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
            "...          ...        ...                                                ...\n",
            "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
            "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
            "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
            "24998  \"10194_3\"          0  \"This 30 minute documentary BuÃ±uel made in the...\n",
            "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
            "\n",
            "[25000 rows x 3 columns]>\n",
            "<bound method NDFrame.head of                id                                             review\n",
            "0      \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
            "1        \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
            "2        \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
            "3        \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
            "4       \"12128_7\"  \"A very accurate depiction of small time mob l...\n",
            "...           ...                                                ...\n",
            "24995   \"2155_10\"  \"Sony Pictures Classics, I'm looking at you! S...\n",
            "24996     \"59_10\"  \"I always felt that Ms. Merkerson had never go...\n",
            "24997    \"2531_1\"  \"I was so disappointed in this movie. I am ver...\n",
            "24998    \"7772_8\"  \"From the opening sequence, filled with black ...\n",
            "24999  \"11465_10\"  \"This is a great horror film for people who do...\n",
            "\n",
            "[25000 rows x 2 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JG1KtGzrNKN"
      },
      "source": [
        "# Data Cleaning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNJi3tXkjrLO"
      },
      "source": [
        "Gensim preprocessing doc: https://radimrehurek.com/gensim/parsing/preprocessing.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WsvEJ3GtSL6",
        "outputId": "4af1c4f8-cdbc-41dd-b7b8-3ae050cfe68a"
      },
      "source": [
        "import gensim.parsing.preprocessing as gp\n",
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Cast words to lower case; remove HTML tags, puctuation, numbers, short words and meaningless stopwords\n",
        "# Use Porter Stemming e.g. treat \"go\", \"going\", and \"went\" as the same word\n",
        "# Remove stop words here, which are the noise for later average vector\n",
        "FILTERS = [lambda x: x.lower(), gp.strip_tags, gp.strip_punctuation, \n",
        "           gp.strip_multiple_whitespaces, gp.strip_short, gp.stem_text, \n",
        "           gp.remove_stopwords, gp.strip_numeric] # maybe not remove number as well\n",
        "\n",
        "# clean a sentence, return a list of words\n",
        "def clean_sentence(raw_sentence):\n",
        "  return preprocess_string(raw_sentence, FILTERS)\n",
        "\n",
        "r1 = train_data[\"review\"][0]\n",
        "print(\"Before: \", r1)\n",
        "print(\"After: \", clean_sentence(r1))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before:  \"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n",
            "After:  ['thi', 'stuff', 'moment', 'start', 'listen', 'hi', 'music', 'watch', 'odd', 'documentari', 'watch', 'wiz', 'watch', 'moonwalk', 'mayb', 'want', 'certain', 'insight', 'thi', 'gui', 'thought', 'wa', 'realli', 'cool', 'eighti', 'mayb', 'mind', 'guilti', 'innoc', 'moonwalk', 'biographi', 'featur', 'film', 'rememb', 'cinema', 'wa', 'origin', 'releas', 'ha', 'subtl', 'messag', 'feel', 'press', 'obviou', 'messag', 'drug', 'ar', 'bad', 'kai', 'visual', 'impress', 'cours', 'thi', 'michael', 'jackson', 'remot', 'like', 'anywai', 'ar', 'hate', 'thi', 'bore', 'mai', 'egotist', 'consent', 'thi', 'movi', 'hi', 'fan', 'sai', 'fan', 'true', 'realli', 'nice', 'actual', 'featur', 'film', 'bit', 'final', 'start', 'onli', 'minut', 'exclud', 'smooth', 'crimin', 'sequenc', 'joe', 'pesci', 'convinc', 'psychopath', 'power', 'drug', 'lord', 'want', 'dead', 'bad', 'becaus', 'overheard', 'hi', 'plan', 'nah', 'joe', 'pesci', 'charact', 'rant', 'want', 'peopl', 'know', 'suppli', 'drug', 'dunno', 'mayb', 'hate', 'music', 'lot', 'cool', 'thing', 'thi', 'like', 'turn', 'car', 'robot', 'speed', 'demon', 'sequenc', 'director', 'patienc', 'saint', 'came', 'film', 'kiddi', 'bad', 'sequenc', 'usual', 'director', 'hate', 'work', 'kid', 'let', 'alon', 'bunch', 'perform', 'complex', 'danc', 'scene', 'line', 'thi', 'movi', 'peopl', 'like', 'level', 'anoth', 'think', 'peopl', 'stai', 'awai', 'doe', 'try', 'wholesom', 'messag', 'iron', 'bestest', 'buddi', 'thi', 'movi', 'girl', 'michael', 'jackson', 'truli', 'talent', 'peopl', 'grace', 'thi', 'planet', 'guilti', 'attent', 'gave', 'thi', 'subject', 'hmmm', 'know', 'becaus', 'peopl', 'differ', 'close', 'door', 'know', 'thi', 'fact', 'extrem', 'nice', 'stupid', 'gui', 'sickest', 'liar', 'hope']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnEAyrFJYWVF"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDRO7ImsX8Dq"
      },
      "source": [
        "Word2Vec expects single sentences as inputs, each one as a list of words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4I1FY_za7DE",
        "outputId": "bb70103e-bb31-4508-e678-e76b8e398884"
      },
      "source": [
        "from gensim.summarization.textcleaner import split_sentences\n",
        "\n",
        "# split a review by sentences, return a list of sentences, for each is a list of words\n",
        "def split_review (raw_review):\n",
        "  raw_sentences = split_sentences(raw_review)\n",
        "  clean_sentences = []\n",
        "  for s in raw_sentences:\n",
        "    if len(s) > 0:\n",
        "      clean_sentences.append( clean_sentence(s))\n",
        "  return clean_sentences\n",
        "\n",
        "print(\"Before: \", r1)\n",
        "print(\"After: \", split_review(r1))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before:  \"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n",
            "After:  [['thi', 'stuff', 'moment', 'start', 'listen', 'hi', 'music', 'watch', 'odd', 'documentari', 'watch', 'wiz', 'watch', 'moonwalk'], ['mayb', 'want', 'certain', 'insight', 'thi', 'gui', 'thought', 'wa', 'realli', 'cool', 'eighti', 'mayb', 'mind', 'guilti', 'innoc'], ['moonwalk', 'biographi', 'featur', 'film', 'rememb', 'cinema', 'wa', 'origin', 'releas'], ['ha', 'subtl', 'messag', 'feel', 'press', 'obviou', 'messag', 'drug', 'ar', 'bad', 'kai', 'visual', 'impress', 'cours', 'thi', 'michael', 'jackson', 'remot', 'like', 'anywai', 'ar', 'hate', 'thi', 'bore'], ['mai', 'egotist', 'consent', 'thi', 'movi', 'hi', 'fan', 'sai', 'fan', 'true', 'realli', 'nice', 'actual', 'featur', 'film', 'bit', 'final', 'start', 'onli', 'minut', 'exclud', 'smooth', 'crimin', 'sequenc', 'joe', 'pesci', 'convinc', 'psychopath', 'power', 'drug', 'lord'], ['want', 'dead', 'bad'], ['becaus', 'overheard', 'hi', 'plan'], ['nah', 'joe', 'pesci', 'charact', 'rant', 'want', 'peopl', 'know', 'suppli', 'drug', 'dunno', 'mayb', 'hate', 'music', 'lot', 'cool', 'thing', 'thi', 'like', 'turn', 'car', 'robot', 'speed', 'demon', 'sequenc'], ['director', 'patienc', 'saint', 'came', 'film', 'kiddi', 'bad', 'sequenc', 'usual', 'director', 'hate', 'work', 'kid', 'let', 'alon', 'bunch', 'perform', 'complex', 'danc', 'scene', 'line', 'thi', 'movi', 'peopl', 'like', 'level', 'anoth', 'think', 'peopl'], ['stai', 'awai'], ['doe', 'try', 'wholesom', 'messag', 'iron', 'bestest', 'buddi', 'thi', 'movi', 'girl'], ['michael', 'jackson', 'truli', 'talent', 'peopl', 'grace', 'thi', 'planet', 'guilti'], ['attent', 'gave', 'thi', 'subject', 'hmmm', 'know', 'becaus', 'peopl', 'differ', 'close', 'door', 'know', 'thi', 'fact'], ['extrem', 'nice', 'stupid', 'gui', 'sickest', 'liar'], ['hope']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSg3RlZEZyqu",
        "outputId": "d36934ef-5048-47df-aaf2-682664fa5e53"
      },
      "source": [
        "# prepare input data for Word2Vec (takes couple minutes):\n",
        "all_sentences = []  \n",
        "\n",
        "print(f'Parsing {len(train_data[\"review\"])} sentences from training set...')\n",
        "train_size = len(train_data[\"review\"])\n",
        "for i in range (0, train_size):\n",
        "    # report progress\n",
        "    progress = (i+1)/train_size *100\n",
        "    if( progress%20 == 0 ):\n",
        "        print(f'   {progress}%')  \n",
        "    all_sentences += split_review( train_data[\"review\"][i])\n",
        "\n",
        "print(f'Parsing {len(unlabeled_train[\"review\"])} sentences from unlabeled set...')\n",
        "unlabel_size = len(unlabeled_train[\"review\"])\n",
        "for i in range (0, unlabel_size):\n",
        "    # report progress\n",
        "    progress = (i+1)/unlabel_size *100\n",
        "    if( progress%20 == 0 ):\n",
        "        print(f'   {progress}%')  \n",
        "    all_sentences += split_review(unlabeled_train[\"review\"][i])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing 25000 sentences from training set...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n",
            "Parsing 50000 sentences from unlabeled set...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGEFvNrkZZC",
        "outputId": "36db3800-aac3-4c59-8e22-e688574cb22e"
      },
      "source": [
        "print(\"Total:\", len(all_sentences), \"sentences\")\n",
        "print(all_sentences[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total: 792761 sentences\n",
            "['thi', 'stuff', 'moment', 'start', 'listen', 'hi', 'music', 'watch', 'odd', 'documentari', 'watch', 'wiz', 'watch', 'moonwalk']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMNTIb77DKXy"
      },
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15U8kEvAlvIw"
      },
      "source": [
        "## 1. Word2Vec "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFEnbCJmbQf",
        "outputId": "2b30baa5-9e4d-42b2-b6d5-9b2d4df0a886"
      },
      "source": [
        "# Output messages for training\n",
        "from gensim.models import word2vec\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',\n",
        "    level=logging.INFO,\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    stream=sys.stdout,\n",
        ")\n",
        "log = logging.getLogger('notebook')\n",
        "\n",
        "# parameters\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# model training\n",
        "word2vec_model = word2vec.Word2Vec(all_sentences, workers=num_workers, \n",
        "            size=num_features, min_count = min_word_count, \n",
        "            window = context, sample = downsampling)\n",
        "\n",
        "word2vec_model.init_sims(replace=True) # internally calculates unit-length normalized vectors"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - collecting all words and their counts\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #10000, processed 111865 words, keeping 12374 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #20000, processed 223633 words, keeping 17075 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #30000, processed 332303 words, keeping 20504 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #40000, processed 443349 words, keeping 23280 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #50000, processed 553570 words, keeping 25640 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #60000, processed 662342 words, keeping 27632 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #70000, processed 771713 words, keeping 29389 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #80000, processed 879000 words, keeping 31038 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #90000, processed 989582 words, keeping 32723 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #100000, processed 1098363 words, keeping 34111 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #110000, processed 1207523 words, keeping 35424 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #120000, processed 1316330 words, keeping 36820 word types\n",
            "2021-03-12 00:07:44 [INFO] gensim.models.word2vec - PROGRESS: at sentence #130000, processed 1423969 words, keeping 38032 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #140000, processed 1532779 words, keeping 39201 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #150000, processed 1642755 words, keeping 40381 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #160000, processed 1752564 words, keeping 41509 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #170000, processed 1861126 words, keeping 42555 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #180000, processed 1968734 words, keeping 43527 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #190000, processed 2079167 words, keeping 44441 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #200000, processed 2189077 words, keeping 45315 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #210000, processed 2299632 words, keeping 46302 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #220000, processed 2408825 words, keeping 47227 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #230000, processed 2518022 words, keeping 48138 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #240000, processed 2628710 words, keeping 49037 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #250000, processed 2732799 words, keeping 49933 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #260000, processed 2842278 words, keeping 50747 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #270000, processed 2951205 words, keeping 51810 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #280000, processed 3061234 words, keeping 53098 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #290000, processed 3171588 words, keeping 54197 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #300000, processed 3283059 words, keeping 55214 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #310000, processed 3392863 words, keeping 56265 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #320000, processed 3504986 words, keeping 57310 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #330000, processed 3614057 words, keeping 58306 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #340000, processed 3725898 words, keeping 59257 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #350000, processed 3834907 words, keeping 60202 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #360000, processed 3943290 words, keeping 61056 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #370000, processed 4055306 words, keeping 61953 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #380000, processed 4166123 words, keeping 62829 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #390000, processed 4278862 words, keeping 63612 word types\n",
            "2021-03-12 00:07:45 [INFO] gensim.models.word2vec - PROGRESS: at sentence #400000, processed 4388418 words, keeping 64438 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #410000, processed 4497015 words, keeping 65180 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #420000, processed 4606944 words, keeping 66026 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #430000, processed 4719630 words, keeping 66836 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #440000, processed 4829524 words, keeping 67645 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #450000, processed 4939881 words, keeping 68464 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #460000, processed 5053565 words, keeping 69288 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #470000, processed 5165077 words, keeping 69986 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #480000, processed 5274722 words, keeping 70751 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #490000, processed 5384921 words, keeping 71514 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #500000, processed 5493938 words, keeping 72235 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #510000, processed 5603350 words, keeping 72965 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #520000, processed 5712845 words, keeping 73667 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #530000, processed 5824274 words, keeping 74319 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #540000, processed 5932585 words, keeping 74998 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #550000, processed 6044561 words, keeping 75691 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #560000, processed 6153642 words, keeping 76362 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #570000, processed 6264745 words, keeping 77013 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #580000, processed 6373862 words, keeping 77662 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #590000, processed 6484029 words, keeping 78350 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #600000, processed 6593143 words, keeping 78935 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #610000, processed 6703636 words, keeping 79618 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #620000, processed 6814774 words, keeping 80183 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #630000, processed 6923100 words, keeping 80800 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #640000, processed 7032117 words, keeping 81439 word types\n",
            "2021-03-12 00:07:46 [INFO] gensim.models.word2vec - PROGRESS: at sentence #650000, processed 7143117 words, keeping 82104 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #660000, processed 7251921 words, keeping 82664 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #670000, processed 7360788 words, keeping 83223 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #680000, processed 7471598 words, keeping 83781 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #690000, processed 7581682 words, keeping 84419 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #700000, processed 7693192 words, keeping 85011 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #710000, processed 7802309 words, keeping 85547 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #720000, processed 7911794 words, keeping 86089 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #730000, processed 8023367 words, keeping 86623 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #740000, processed 8132079 words, keeping 87193 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #750000, processed 8240876 words, keeping 87708 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #760000, processed 8348745 words, keeping 88231 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #770000, processed 8460323 words, keeping 88796 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #780000, processed 8571962 words, keeping 89313 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - PROGRESS: at sentence #790000, processed 8683591 words, keeping 89928 word types\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - collected 90089 word types from a corpus of 8713525 raw words and 792761 sentences\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - Loading a fresh vocabulary\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - effective_min_count=40 retains 11812 unique words (13% of original 90089, drops 78277)\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - effective_min_count=40 leaves 8341634 word corpus (95% of original 8713525, drops 371891)\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - deleting the raw counts dictionary of 90089 items\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - sample=0.001 downsamples 33 most-common words\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - downsampling leaves estimated 7480613 word corpus (89.7% of prior 8341634)\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.base_any2vec - estimated required memory for 11812 words and 300 dimensions: 34254800 bytes\n",
            "2021-03-12 00:07:47 [INFO] gensim.models.word2vec - resetting layer weights\n",
            "2021-03-12 00:07:50 [INFO] gensim.models.base_any2vec - training model with 4 workers on 11812 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
            "2021-03-12 00:07:51 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 4.35% examples, 322313 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:07:52 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 8.92% examples, 322455 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:07:53 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 13.67% examples, 329148 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:07:54 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 18.18% examples, 329778 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:07:55 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 22.81% examples, 331027 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:07:56 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 27.29% examples, 331047 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:07:57 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 32.05% examples, 332495 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:07:58 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 36.87% examples, 334442 words/s, in_qsize 8, out_qsize 1\n",
            "2021-03-12 00:07:59 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 41.44% examples, 335303 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:00 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 45.89% examples, 334996 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:01 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 50.44% examples, 335446 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:02 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 55.00% examples, 335078 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:03 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 59.51% examples, 335464 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:04 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 63.99% examples, 334844 words/s, in_qsize 8, out_qsize 2\n",
            "2021-03-12 00:08:05 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 68.60% examples, 335264 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:08:06 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 73.28% examples, 335781 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:07 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 77.86% examples, 336179 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:08 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 82.34% examples, 336088 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:09 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 87.04% examples, 336150 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:10 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 91.72% examples, 336212 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:11 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 96.13% examples, 335670 words/s, in_qsize 7, out_qsize 1\n",
            "2021-03-12 00:08:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:08:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:08:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:08:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:08:12 [INFO] gensim.models.base_any2vec - EPOCH - 1 : training on 8713525 raw words (7480471 effective words) took 22.2s, 336874 effective words/s\n",
            "2021-03-12 00:08:13 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 4.46% examples, 315006 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:14 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 9.16% examples, 322989 words/s, in_qsize 7, out_qsize 1\n",
            "2021-03-12 00:08:15 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 13.89% examples, 327739 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:16 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 18.41% examples, 326684 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:17 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 22.93% examples, 327582 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:18 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 27.40% examples, 328325 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:19 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 31.70% examples, 326552 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:20 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 36.31% examples, 328108 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:21 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 40.74% examples, 328431 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:22 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 45.33% examples, 329468 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:23 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 49.72% examples, 329248 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:24 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 54.53% examples, 329917 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:25 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 59.06% examples, 330694 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:26 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 63.43% examples, 330162 words/s, in_qsize 7, out_qsize 1\n",
            "2021-03-12 00:08:27 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 68.14% examples, 330739 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:28 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 72.47% examples, 330186 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:29 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 76.84% examples, 329462 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:30 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 81.53% examples, 330644 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:31 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 86.25% examples, 330279 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:32 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 91.05% examples, 331513 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 95.81% examples, 331721 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:08:34 [INFO] gensim.models.base_any2vec - EPOCH - 2 : training on 8713525 raw words (7481223 effective words) took 22.5s, 332128 effective words/s\n",
            "2021-03-12 00:08:35 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 4.23% examples, 308380 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:37 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 8.92% examples, 325555 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:38 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 13.66% examples, 333010 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:39 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 18.29% examples, 331977 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:40 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 23.16% examples, 334881 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:41 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 27.63% examples, 334438 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:42 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 32.27% examples, 335546 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:43 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 36.76% examples, 334419 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:08:44 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 41.42% examples, 335415 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:45 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 46.23% examples, 336853 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:46 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 50.77% examples, 336463 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:47 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 55.46% examples, 337022 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:48 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 60.08% examples, 336854 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:49 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 64.46% examples, 335989 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:50 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 68.93% examples, 335605 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:51 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 73.62% examples, 336268 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:52 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 78.19% examples, 336364 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:53 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 82.91% examples, 336198 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:08:54 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 87.51% examples, 336325 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:55 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 92.18% examples, 336911 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:56 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 96.81% examples, 336812 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:08:57 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:08:57 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:08:57 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:08:57 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:08:57 [INFO] gensim.models.base_any2vec - EPOCH - 3 : training on 8713525 raw words (7481064 effective words) took 22.2s, 337647 effective words/s\n",
            "2021-03-12 00:08:58 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 4.45% examples, 318045 words/s, in_qsize 8, out_qsize 3\n",
            "2021-03-12 00:08:59 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 9.04% examples, 328202 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:00 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 13.90% examples, 333876 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:01 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 18.75% examples, 337130 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:02 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 23.39% examples, 335424 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:03 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 28.08% examples, 336327 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:04 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 32.74% examples, 337060 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:05 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 37.32% examples, 337519 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:06 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 41.76% examples, 337195 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:07 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 46.46% examples, 338022 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:08 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 51.35% examples, 338172 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:09:09 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 55.80% examples, 337752 words/s, in_qsize 7, out_qsize 1\n",
            "2021-03-12 00:09:10 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 60.33% examples, 337554 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:11 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 64.91% examples, 337528 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:12 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 69.49% examples, 337623 words/s, in_qsize 7, out_qsize 1\n",
            "2021-03-12 00:09:13 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 74.18% examples, 338016 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:14 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 78.79% examples, 337980 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:15 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 83.61% examples, 338037 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:16 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 88.29% examples, 338135 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:17 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 92.89% examples, 337918 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:18 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 97.48% examples, 337983 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:19 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:09:19 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:09:19 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:09:19 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:09:19 [INFO] gensim.models.base_any2vec - EPOCH - 4 : training on 8713525 raw words (7480597 effective words) took 22.1s, 338707 effective words/s\n",
            "2021-03-12 00:09:20 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 4.46% examples, 330423 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:09:21 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 9.03% examples, 326542 words/s, in_qsize 4, out_qsize 3\n",
            "2021-03-12 00:09:22 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 13.89% examples, 335239 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:23 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 18.52% examples, 336360 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:24 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 23.39% examples, 339649 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:25 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 27.97% examples, 339257 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:26 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 32.62% examples, 339340 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:27 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 37.44% examples, 338469 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:28 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 42.22% examples, 339719 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:29 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 46.90% examples, 340674 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:30 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 51.48% examples, 339869 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:31 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 56.13% examples, 340757 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:32 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 60.65% examples, 339571 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:33 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 65.48% examples, 340329 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:34 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 70.08% examples, 339812 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:35 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 74.65% examples, 339976 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:36 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 79.24% examples, 340080 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:37 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 83.95% examples, 339755 words/s, in_qsize 6, out_qsize 1\n",
            "2021-03-12 00:09:38 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 88.75% examples, 340057 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:39 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 93.46% examples, 340149 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:40 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 98.04% examples, 340021 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - EPOCH - 5 : training on 8713525 raw words (7480412 effective words) took 22.0s, 340694 effective words/s\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.base_any2vec - training on a 43567625 raw words (37403767 effective words) took 111.0s, 336967 effective words/s\n",
            "2021-03-12 00:09:41 [INFO] gensim.models.keyedvectors - precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAzZkVCWubxD",
        "outputId": "0a5cfe32-d1c7-4e1e-9633-fa0e4f36ab59"
      },
      "source": [
        "# save model to drive for later use OPTIONAL\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def save_model(model, name):\n",
        "  model_save_name = f'{name}({num_features},{min_word_count},{context})'\n",
        "  path = f\"/content/drive/MyDrive/{model_save_name}\" \n",
        "  model.save(path)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACqUOtywkZb",
        "outputId": "b8b204a1-c2cf-43dc-e733-b2dd2f2a3402"
      },
      "source": [
        "save_model(word2vec_model, \"Word2Vec\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-12 00:10:17 [INFO] gensim.utils - saving Word2Vec object under /content/drive/MyDrive/Word2Vec(300,40,10), separately None\n",
            "2021-03-12 00:10:17 [INFO] gensim.utils - not storing attribute vectors_norm\n",
            "2021-03-12 00:10:17 [INFO] gensim.utils - not storing attribute cum_table\n",
            "2021-03-12 00:10:19 [INFO] gensim.utils - saved /content/drive/MyDrive/Word2Vec(300,40,10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghysJ0p6y2Qv"
      },
      "source": [
        "load trained Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAs-vbdyizc"
      },
      "source": [
        "# load trained model OPTIONAL\n",
        "from gensim.models import Word2Vec\n",
        "word2vec_model = Word2Vec.load(\"Word2Vec(300,40,10)\")\n",
        "word2vec_model.trainables.syn1neg.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq-zQbNNza8J",
        "outputId": "b271774a-68cc-4cfa-f442-4a83cec86592"
      },
      "source": [
        "word2vec_model.wv[\"man\"] # word vec"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00790779, -0.00668373,  0.01135651,  0.05575463, -0.04172793,\n",
              "       -0.02518707, -0.02800363,  0.01221512,  0.01416656, -0.03569898,\n",
              "       -0.05336002,  0.00683461,  0.09737637, -0.01613286, -0.02946621,\n",
              "        0.01263367,  0.08575792,  0.03461728, -0.03028729, -0.05556952,\n",
              "       -0.0234124 ,  0.04086632,  0.02783649, -0.06073735,  0.06068921,\n",
              "        0.01167279,  0.08543117, -0.04580932,  0.02434501, -0.02314274,\n",
              "        0.08592816,  0.01512182,  0.06692058,  0.01390861, -0.08533301,\n",
              "       -0.06960441, -0.00121154,  0.03295327, -0.00071125, -0.06146927,\n",
              "       -0.04905044, -0.10266563, -0.04576875,  0.10780175,  0.06847   ,\n",
              "        0.09984921, -0.00564327,  0.04405795, -0.0087141 ,  0.06850781,\n",
              "       -0.00908569, -0.03732553, -0.00051461,  0.00761091, -0.01683275,\n",
              "       -0.01396136, -0.14533119, -0.06501181, -0.10504609,  0.08648138,\n",
              "       -0.00426058, -0.07482792, -0.07241637, -0.03257763,  0.00865732,\n",
              "        0.09045486, -0.10897283,  0.04535472,  0.08304214, -0.03880759,\n",
              "        0.00328672, -0.00987738, -0.08388955,  0.01031742, -0.04742251,\n",
              "        0.01953446,  0.01186883,  0.01275075, -0.02497782, -0.09063821,\n",
              "       -0.04570646, -0.01219177,  0.03485554, -0.05047372, -0.16269934,\n",
              "       -0.00662946, -0.02260584,  0.05212961, -0.02666717, -0.00440339,\n",
              "        0.01824896,  0.01106073, -0.00137441, -0.04516615, -0.04123168,\n",
              "       -0.07165634,  0.01767444,  0.08842023, -0.1287316 ,  0.07536407,\n",
              "       -0.10114104, -0.02768279,  0.04326975, -0.06401674, -0.02475781,\n",
              "       -0.03973882, -0.01012996,  0.06144142, -0.05623326,  0.00177596,\n",
              "       -0.00380311,  0.04559676,  0.10566636,  0.0411862 ,  0.00999259,\n",
              "       -0.06134427,  0.03252895, -0.01573108,  0.03932901,  0.09887666,\n",
              "       -0.05631601,  0.02306281, -0.00591238, -0.10576173,  0.00729817,\n",
              "       -0.05086827, -0.20423849, -0.00848559,  0.07772577,  0.00876586,\n",
              "       -0.03454672, -0.00966519, -0.16078557,  0.01976972,  0.03411458,\n",
              "        0.01273039, -0.0230628 , -0.08175983, -0.05734366,  0.01182321,\n",
              "       -0.01438234, -0.01679323,  0.03846936,  0.03852443,  0.04059034,\n",
              "        0.02519836,  0.01863392, -0.0095895 , -0.03898184,  0.02881183,\n",
              "        0.01958277, -0.07782817,  0.04835059,  0.09493864,  0.06566279,\n",
              "        0.04541982, -0.00527014,  0.08026315,  0.10770941, -0.08016714,\n",
              "        0.01947433, -0.11127643, -0.04814589, -0.05785353, -0.04303288,\n",
              "       -0.00826682, -0.06876674,  0.02275625,  0.04908138,  0.00648235,\n",
              "       -0.02974558, -0.04812071,  0.02604349,  0.08096709,  0.0049496 ,\n",
              "       -0.04231139, -0.00878537, -0.10936743,  0.01864175,  0.03252461,\n",
              "       -0.0175219 , -0.12367265,  0.04469949,  0.01706084, -0.02014632,\n",
              "        0.06199809, -0.04618221, -0.12088256, -0.04775558,  0.02966504,\n",
              "       -0.05199566, -0.05012121,  0.07389694, -0.06925225,  0.06857309,\n",
              "       -0.07683954,  0.00021384, -0.00219353,  0.02791742,  0.01786453,\n",
              "        0.00456412,  0.03511729, -0.00331194,  0.00764803,  0.08599313,\n",
              "       -0.06945404, -0.07051005,  0.05992284,  0.0119248 , -0.10628244,\n",
              "       -0.03816523, -0.02722412, -0.05227897,  0.05582771,  0.0179967 ,\n",
              "       -0.01755768,  0.03264198,  0.07000455, -0.02915641, -0.01264345,\n",
              "        0.01727172,  0.08757571, -0.08084866, -0.02290619, -0.06541723,\n",
              "       -0.06574742, -0.10318068, -0.11799334,  0.01415861,  0.00505837,\n",
              "       -0.05903437, -0.02982059,  0.01032813, -0.05840551,  0.01022945,\n",
              "       -0.00892606,  0.1040903 , -0.00787896,  0.00773897,  0.08058886,\n",
              "        0.02627564, -0.01834314, -0.04230417,  0.03615045, -0.03031251,\n",
              "       -0.03465715, -0.01477512, -0.03225297, -0.01663366,  0.03326203,\n",
              "        0.0616491 , -0.03198681,  0.10497694, -0.02326676,  0.01875372,\n",
              "        0.09748967, -0.11141356, -0.14605224, -0.11272803,  0.05473557,\n",
              "        0.06964828,  0.06929144,  0.01011788, -0.01098755,  0.01182995,\n",
              "        0.01073154, -0.05121839, -0.10483994,  0.0281109 ,  0.055283  ,\n",
              "       -0.00532946,  0.00299009,  0.01738948, -0.03632763,  0.12529413,\n",
              "        0.15906125,  0.05226915, -0.01534555,  0.04412673, -0.05396443,\n",
              "        0.05063437,  0.06465163, -0.00205612,  0.02570693,  0.00864978,\n",
              "        0.09130644, -0.05120004, -0.06961848,  0.04331353, -0.02665298,\n",
              "       -0.05261327,  0.02059179,  0.04934679, -0.01931035, -0.03814396,\n",
              "       -0.05846637, -0.09028772, -0.09561544, -0.0290654 , -0.01477705],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzsT36mdp5To",
        "outputId": "2bfe9f4a-183f-42db-ce63-7e56a597731e"
      },
      "source": [
        "word2vec_model.wv.most_similar(\"woman\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('women', 0.6129238605499268),\n",
              " ('giovanna', 0.5904942750930786),\n",
              " ('prostitut', 0.5829073786735535),\n",
              " ('ladi', 0.5744413733482361),\n",
              " ('loretta', 0.5725628733634949),\n",
              " ('lass', 0.563113808631897),\n",
              " ('widow', 0.5628523826599121),\n",
              " ('housewif', 0.5491349101066589),\n",
              " ('whore', 0.544928789138794),\n",
              " ('husband', 0.5417135953903198)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxw7EBbYBY-7"
      },
      "source": [
        "## 2. Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ess9dN1EKFd"
      },
      "source": [
        "\n",
        "Gensim Doc2Vec doc https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6vBGdRlXgT4"
      },
      "source": [
        "Doc2Vec preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HmziqdeHmIP",
        "outputId": "da79d8e0-d92d-42f6-ff8f-8233ab9018ae"
      },
      "source": [
        "import gensim.utils\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# prepare input data for Doc2Vec (takes couple minutes):\n",
        "taggeddoc = []  \n",
        "\n",
        "print(f'Parsing {len(train_data[\"review\"])} sentences from training set...')\n",
        "train_size = len(train_data[\"review\"])\n",
        "for i in range (0, train_size):\n",
        "    # report progress\n",
        "    progress = (i+1)/train_size *100\n",
        "    if( progress%20 == 0 ):\n",
        "        print(f'   {progress}%')  \n",
        "    clean_r = clean_sentence( train_data[\"review\"][i])\n",
        "    taggeddoc.append(TaggedDocument(gensim.utils.to_unicode(str.encode(' '.join(clean_r))).split(),str(i)))\n",
        "\n",
        "print(f'Parsing {len(unlabeled_train[\"review\"])} sentences from unlabeled_train set...')\n",
        "unlabeled_train_size = len(unlabeled_train[\"review\"])\n",
        "for i in range (0, unlabeled_train_size):\n",
        "    # report progress\n",
        "    progress = (i+1)/unlabeled_train_size *100\n",
        "    if( progress%20 == 0 ):\n",
        "        print(f'   {progress}%')  \n",
        "    clean_r = clean_sentence( unlabeled_train[\"review\"][i])\n",
        "    taggeddoc.append(TaggedDocument(gensim.utils.to_unicode(str.encode(' '.join(clean_r))).split(),str(i)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing 25000 sentences from training set...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n",
            "Parsing 50000 sentences from unlabeled_train set...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt4aVk_eXc7a"
      },
      "source": [
        "Doc2Vec training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsgUw29uBdo2",
        "outputId": "bd7d242a-8d61-4efc-cbb6-f7057815c5f3"
      },
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "# output messages\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',\n",
        "    level=logging.INFO,\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    stream=sys.stdout,\n",
        ")\n",
        "log = logging.getLogger('notebook')\n",
        "\n",
        "# parameters\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# model training\n",
        "doc2vec_model = Doc2Vec(taggeddoc, workers=num_workers, \n",
        "                        vector_size= num_features, min_count = min_word_count, \n",
        "                        window = context, sample = downsampling)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-12 00:13:57 [INFO] gensim.models.doc2vec - collecting all words and their counts\n",
            "2021-03-12 00:13:57 [INFO] gensim.models.doc2vec - PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2021-03-12 00:13:58 [INFO] gensim.models.doc2vec - PROGRESS: at example #10000, processed 1169086 words (2282547/s), 34946 word types, 10 tags\n",
            "2021-03-12 00:13:58 [INFO] gensim.models.doc2vec - PROGRESS: at example #20000, processed 2322701 words (2387794/s), 46493 word types, 10 tags\n",
            "2021-03-12 00:13:59 [INFO] gensim.models.doc2vec - PROGRESS: at example #30000, processed 3474171 words (2842950/s), 57058 word types, 10 tags\n",
            "2021-03-12 00:13:59 [INFO] gensim.models.doc2vec - PROGRESS: at example #40000, processed 4634266 words (2856544/s), 66247 word types, 10 tags\n",
            "2021-03-12 00:13:59 [INFO] gensim.models.doc2vec - PROGRESS: at example #50000, processed 5809170 words (2877870/s), 74232 word types, 10 tags\n",
            "2021-03-12 00:14:00 [INFO] gensim.models.doc2vec - PROGRESS: at example #60000, processed 6976277 words (2871240/s), 81100 word types, 10 tags\n",
            "2021-03-12 00:14:00 [INFO] gensim.models.doc2vec - PROGRESS: at example #70000, processed 8132122 words (2772635/s), 87197 word types, 10 tags\n",
            "2021-03-12 00:14:00 [INFO] gensim.models.doc2vec - collected 90091 word types and 10 unique tags from a corpus of 75000 examples and 8713347 words\n",
            "2021-03-12 00:14:00 [INFO] gensim.models.word2vec - Loading a fresh vocabulary\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - effective_min_count=40 retains 11812 unique words (13% of original 90091, drops 78279)\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - effective_min_count=40 leaves 8341459 word corpus (95% of original 8713347, drops 371888)\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - deleting the raw counts dictionary of 90091 items\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - sample=0.001 downsamples 33 most-common words\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - downsampling leaves estimated 7480452 word corpus (89.7% of prior 8341459)\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.base_any2vec - estimated required memory for 11812 words and 300 dimensions: 34268800 bytes\n",
            "2021-03-12 00:14:01 [INFO] gensim.models.word2vec - resetting layer weights\n",
            "2021-03-12 00:14:03 [INFO] gensim.models.base_any2vec - training model with 4 workers on 11812 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
            "2021-03-12 00:14:04 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 2.83% examples, 200812 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:05 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 5.71% examples, 208926 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:06 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 8.47% examples, 207620 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:07 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 11.39% examples, 212747 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:08 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 14.14% examples, 210296 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:09 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 16.74% examples, 209022 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:10 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 19.66% examples, 209968 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:11 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 22.46% examples, 209544 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:12 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 25.19% examples, 209944 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:13 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 27.94% examples, 210257 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:14 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 30.60% examples, 209466 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:16 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 33.55% examples, 210156 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:17 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 36.49% examples, 210536 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:18 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 39.27% examples, 210440 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:19 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 42.05% examples, 210506 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:20 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 44.66% examples, 209850 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:21 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 47.51% examples, 209845 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:22 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 50.21% examples, 209787 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:23 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 52.84% examples, 209526 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:24 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 55.42% examples, 209245 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:25 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 58.13% examples, 208949 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:26 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 60.91% examples, 209006 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:27 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 63.69% examples, 208902 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:28 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 66.43% examples, 209110 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:29 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 68.94% examples, 208456 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:30 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 71.76% examples, 208906 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:31 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 74.46% examples, 209077 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:32 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 77.02% examples, 208908 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:33 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 79.78% examples, 209047 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:34 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 82.55% examples, 209047 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:35 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 85.26% examples, 208849 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:36 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 88.04% examples, 208828 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:37 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 91.04% examples, 209180 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:38 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 93.75% examples, 209118 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:39 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 96.46% examples, 209274 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - EPOCH 1 - PROGRESS: at 99.33% examples, 209660 words/s, in_qsize 6, out_qsize 0\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:14:40 [INFO] gensim.models.base_any2vec - EPOCH - 1 : training on 8713347 raw words (7832713 effective words) took 37.4s, 209678 effective words/s\n",
            "2021-03-12 00:14:42 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 2.83% examples, 202533 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:43 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 5.71% examples, 212690 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:44 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 8.47% examples, 211928 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:45 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 11.39% examples, 212581 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:46 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 14.14% examples, 212341 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:47 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 16.74% examples, 211252 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:48 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 19.34% examples, 208712 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:49 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 22.12% examples, 208444 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:50 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 24.61% examples, 207139 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:51 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 27.39% examples, 207617 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:52 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 29.89% examples, 206635 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:53 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 32.71% examples, 206382 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:14:54 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 35.57% examples, 207111 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:55 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 38.22% examples, 206684 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:56 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 41.09% examples, 206862 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:57 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 43.86% examples, 206736 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:58 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 46.70% examples, 207396 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:14:59 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 49.24% examples, 206826 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:00 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 51.94% examples, 207185 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:01 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 54.53% examples, 207055 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:02 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 57.26% examples, 206985 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:03 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 59.89% examples, 207088 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:04 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 62.59% examples, 207078 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:05 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 65.28% examples, 206901 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:06 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 68.16% examples, 207381 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:07 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 70.85% examples, 207366 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:08 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 73.54% examples, 207597 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:09 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 76.11% examples, 207231 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:10 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 78.76% examples, 207157 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:11 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 81.49% examples, 206939 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:12 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 84.26% examples, 207034 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:13 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 87.05% examples, 206881 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:14 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 89.72% examples, 206920 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:15 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 92.55% examples, 207010 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:16 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 95.25% examples, 206965 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:17 [INFO] gensim.models.base_any2vec - EPOCH 2 - PROGRESS: at 97.92% examples, 207105 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:18 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:15:18 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:15:18 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:15:18 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:15:18 [INFO] gensim.models.base_any2vec - EPOCH - 2 : training on 8713347 raw words (7833436 effective words) took 37.8s, 207447 effective words/s\n",
            "2021-03-12 00:15:19 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 2.48% examples, 189532 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:20 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 5.25% examples, 197841 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:21 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 8.01% examples, 201802 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:22 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 10.83% examples, 204454 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:23 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 13.57% examples, 205185 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:24 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 16.29% examples, 206015 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:25 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 18.98% examples, 206453 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:26 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 21.79% examples, 206720 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:27 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 24.50% examples, 206578 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:29 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 27.39% examples, 205753 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:30 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 30.13% examples, 205582 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:31 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 32.95% examples, 204992 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:32 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 35.78% examples, 205960 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:33 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 38.68% examples, 206661 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:34 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 41.45% examples, 206938 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:35 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 44.18% examples, 206521 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:36 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 46.81% examples, 206275 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:37 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 49.55% examples, 206017 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:38 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 52.29% examples, 206282 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:39 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 55.08% examples, 206531 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:40 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 57.71% examples, 206387 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:41 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 60.23% examples, 206165 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:42 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 62.83% examples, 205984 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:43 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 65.72% examples, 206874 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:44 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 68.38% examples, 206185 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:45 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 70.96% examples, 206054 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:46 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 73.65% examples, 205986 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:47 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 76.45% examples, 206417 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:48 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 79.22% examples, 206354 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:49 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 81.86% examples, 206229 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:50 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 84.48% examples, 206194 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:51 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 87.16% examples, 206017 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:52 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 89.84% examples, 206156 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:53 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 92.68% examples, 206209 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:54 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 95.36% examples, 206430 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:55 [INFO] gensim.models.base_any2vec - EPOCH 3 - PROGRESS: at 98.04% examples, 206479 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:56 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:15:56 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:15:56 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:15:56 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:15:56 [INFO] gensim.models.base_any2vec - EPOCH - 3 : training on 8713347 raw words (7833203 effective words) took 37.9s, 206829 effective words/s\n",
            "2021-03-12 00:15:57 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 2.81% examples, 192865 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:15:58 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 5.60% examples, 205503 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:15:59 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 8.58% examples, 207635 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:00 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 11.39% examples, 209277 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:16:01 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 14.12% examples, 209865 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:02 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 16.74% examples, 208079 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:03 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 19.44% examples, 208675 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:04 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 22.23% examples, 209296 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:05 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 24.96% examples, 209595 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:06 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 27.50% examples, 208180 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:07 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 30.25% examples, 208549 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:08 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 33.20% examples, 208662 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:10 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 36.00% examples, 209127 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:11 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 38.69% examples, 208562 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:12 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 41.70% examples, 209218 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:13 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 44.42% examples, 209396 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:14 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 47.14% examples, 209224 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:16:15 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 49.87% examples, 209079 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:16 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 52.72% examples, 209618 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:17 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 55.19% examples, 208922 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:18 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 57.90% examples, 208442 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:19 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 60.57% examples, 208652 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:20 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 63.36% examples, 208639 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:21 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 66.29% examples, 208859 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:22 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 69.17% examples, 208873 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:23 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 71.89% examples, 208968 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:24 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 74.57% examples, 209098 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:25 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 77.25% examples, 209139 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:26 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 80.15% examples, 209044 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:27 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 82.87% examples, 208883 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:28 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 85.63% examples, 208789 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:29 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 88.28% examples, 208506 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:30 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 90.93% examples, 208279 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:31 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 93.65% examples, 208000 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:32 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 96.24% examples, 207900 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:33 [INFO] gensim.models.base_any2vec - EPOCH 4 - PROGRESS: at 98.98% examples, 207715 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:16:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:16:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:16:34 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:16:34 [INFO] gensim.models.base_any2vec - EPOCH - 4 : training on 8713347 raw words (7833203 effective words) took 37.7s, 207991 effective words/s\n",
            "2021-03-12 00:16:35 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 2.39% examples, 183034 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:36 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 5.15% examples, 201316 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:37 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 7.86% examples, 202624 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:38 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 10.71% examples, 206548 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:39 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 13.46% examples, 207316 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:40 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 16.17% examples, 206766 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:41 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 18.86% examples, 206787 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:42 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 21.56% examples, 205928 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:43 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 24.29% examples, 206602 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:44 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 27.08% examples, 207161 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:45 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 29.64% examples, 206912 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:46 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 32.47% examples, 207300 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:47 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 35.13% examples, 206950 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:48 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 38.00% examples, 207988 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:49 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 40.62% examples, 207531 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:50 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 43.63% examples, 207379 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:16:51 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 46.49% examples, 208105 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:52 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 49.24% examples, 207768 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:53 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 52.07% examples, 207815 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:54 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 54.75% examples, 207456 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:55 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 57.49% examples, 206958 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:56 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 60.11% examples, 206779 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:16:57 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 62.93% examples, 207188 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:16:58 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 65.62% examples, 207416 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:00 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 68.27% examples, 206829 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:01 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 71.08% examples, 207070 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:02 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 73.65% examples, 206962 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:17:03 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 76.45% examples, 207215 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:04 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 79.22% examples, 207196 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:05 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 81.99% examples, 206789 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:06 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 84.70% examples, 206698 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:07 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 87.38% examples, 206666 words/s, in_qsize 8, out_qsize 0\n",
            "2021-03-12 00:17:08 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 89.85% examples, 206326 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:09 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 92.68% examples, 206374 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:10 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 95.47% examples, 206173 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:11 [INFO] gensim.models.base_any2vec - EPOCH 5 - PROGRESS: at 98.14% examples, 206210 words/s, in_qsize 7, out_qsize 0\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 3 more threads\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - EPOCH - 5 : training on 8713347 raw words (7833474 effective words) took 37.9s, 206704 effective words/s\n",
            "2021-03-12 00:17:12 [INFO] gensim.models.base_any2vec - training on a 43566735 raw words (39166029 effective words) took 188.6s, 207675 effective words/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isg6ihXtxdS_",
        "outputId": "d8d9dd28-a33e-42ab-f8b1-5a53daa66ad0"
      },
      "source": [
        "save_model(doc2vec_model, \"Doc2Vec\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-12 00:17:24 [INFO] gensim.utils - saving Doc2Vec object under /content/drive/MyDrive/Doc2Vec(300,40,10), separately None\n",
            "2021-03-12 00:17:25 [INFO] gensim.utils - saved /content/drive/MyDrive/Doc2Vec(300,40,10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu-Ak0MMPDNI",
        "outputId": "461640d4-54b3-4947-b4c3-39ad4e876912"
      },
      "source": [
        "doc2vec_model.wv.most_similar(\"woman\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-12 00:17:41 [INFO] gensim.models.keyedvectors - precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('women', 0.5527838468551636),\n",
              " ('loretta', 0.5242778658866882),\n",
              " ('ladi', 0.5215874910354614),\n",
              " ('husband', 0.48164546489715576),\n",
              " ('mathieu', 0.47373396158218384),\n",
              " ('conchita', 0.47359904646873474),\n",
              " ('nubil', 0.46975177526474),\n",
              " ('seduc', 0.46744436025619507),\n",
              " ('bisexu', 0.46443110704421997),\n",
              " ('whore', 0.462283194065094)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzcF6VHr3Ez5"
      },
      "source": [
        "# Building Feature Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykK47CbJ8cQk"
      },
      "source": [
        "# same clean process apply to input data, keep consistent with the keys in encoding models vc dic\n",
        "clean_reviews = []\n",
        "\n",
        "for review in train_data[\"review\"]:\n",
        "  clean_reviews.append(clean_sentence(review))"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvJfxeve36Le"
      },
      "source": [
        "get the feature set by averaging the word vectors in a single review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbipgPWQ24_A"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# take a list of words as input, return average vector\n",
        "def get_average_vec(review, model, n_features = num_features):\n",
        "    vectorized = [model.wv[word] for word in review if word in model.wv.vocab]\n",
        "    total = len(vectorized)\n",
        "    sum_v = np.sum(vectorized, axis=0)\n",
        "    average_v = np.divide(sum_v, total)\n",
        "    return average_v"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuPwS9p3Q8hH"
      },
      "source": [
        "def to_feature_set(model, method, reviews):\n",
        "  f_set = []\n",
        "  train_size = len(reviews)\n",
        "  print(f'Processing {train_size} training reviews...')\n",
        "  \n",
        "  for i in range (0, train_size):\n",
        "    # report progress\n",
        "    progress = (i+1)/train_size *100\n",
        "    if( progress%20 == 0 ):\n",
        "        print(f'   {progress}%')  \n",
        "\n",
        "    avg_v = method(reviews[i], model)\n",
        "    f_set.append(avg_v)\n",
        "  return f_set"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q7912PWIHza"
      },
      "source": [
        "Same preprocessing as word2vec to keep input data format uniform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSuLWbWrSjqS",
        "outputId": "3d373414-7db1-4135-cfc0-254432cecace"
      },
      "source": [
        "word2vec_train_reviews = to_feature_set(word2vec_model, get_average_vec, clean_reviews)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 25000 training reviews...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0cVtnbjQ4yu",
        "outputId": "83256fc4-cbd9-46c0-f88c-2999db99061d"
      },
      "source": [
        "doc2vec_train_reviews = to_feature_set(doc2vec_model, get_average_vec, clean_reviews)  "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 25000 training reviews...\n",
            "   20.0%\n",
            "   40.0%\n",
            "   60.0%\n",
            "   80.0%\n",
            "   100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvYIjkHgDVBK"
      },
      "source": [
        "# Classifier Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v_3se6kG0tf"
      },
      "source": [
        "# splitting train test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(word2vec_train_reviews, train_data[\"sentiment\"], \n",
        "                                                    test_size=0.2, random_state=42)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(doc2vec_train_reviews, train_data[\"sentiment\"], \n",
        "                                                    test_size=0.2, random_state=42)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsolHlbcJBkk"
      },
      "source": [
        "## Random forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9jw8VXYDEPs",
        "outputId": "d5aa8908-7cc7-4f79-c0f4-656b21f99a88"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as rfc\n",
        "\n",
        "RF = rfc(n_estimators=100)\n",
        "\n",
        "# train\n",
        "RF1 = RF.fit(X_train1, y_train1)\n",
        "print(\"Word2Vec encoding Test accuracy:\" ,RF.score(X_test1, y_test1))\n",
        "\n",
        "RF2 = RF.fit(X_train2, y_train2)\n",
        "print(\"Doc2Vec encoding Test accuracy:\" ,RF.score(X_test2, y_test2))\n",
        "\n",
        "# predict\n",
        "#result = RF1.predict(y_train)\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec encoding Test accuracy: 0.8384\n",
            "Doc2Vec encoding Test accuracy: 0.8524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CSmWEaBJUGC"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SExMQ4NM-pTo",
        "outputId": "328edb0e-6517-414d-8fbf-d2793ad62d6e"
      },
      "source": [
        "# may take an hour for runing this block\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "C = 10\n",
        "\n",
        "svc_clf = SVC(kernel='linear', C=C, probability=True, random_state=0)\n",
        "\n",
        "svc_clf1 = svc_clf.fit(X_train1, y_train1)\n",
        "print(\"Word2Vec encoding Test accuracy:\" ,svc_clf1.score(X_test1, y_test1))\n",
        "\n",
        "svc_clf2 = svc_clf.fit(X_train2, y_train2)\n",
        "print(\"Doc2Vec encoding Test accuracy:\" ,svc_clf2.score(X_test2, y_test2))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec encoding Test accuracy: 0.8728\n",
            "DocVec encoding Test accuracy: 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuF9LzPCJYGZ"
      },
      "source": [
        "## Bayes"
      ]
    }
  ]
}